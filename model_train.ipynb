{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to detect whether the title and message is real or fake. Data source has a\n",
    "shape of 7796×4. The first column identifies the news, the second and third are the title and\n",
    "text, and the fourth column has labels denoting whether the news is “REAL” or “FAKE”.\n",
    "Dataset Link: https://www.kaggle.com/datasets/hassanamin/textdb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing \n",
    "● Download the data source, named news.csv. \\\n",
    "● Split the dataset to 80% training set and 20% testing set. \\\n",
    "● Check and report the ratio of real-to-fake news are roughly the same in both training\n",
    "and testing sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(dataPath):\n",
    "    \"\"\" \n",
    "    Data preprocessing. \n",
    "    \n",
    "    :param dataPath: str, the path of data file\n",
    "    :returns (x_train, x_test, y_train, y_test): tuple, features and labels for training and testing sets\n",
    "\n",
    "    \"\"\"\n",
    "    print(\"Data Prerpocessing...\")\n",
    "    # read date from file\n",
    "    df = pd.read_csv(dataPath)\n",
    "\n",
    "    # extract features and labels\n",
    "    X = df[['title', 'text']]\n",
    "    y = df['label']\n",
    "\n",
    "    # split the dataset\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, stratify = y, test_size=0.2, random_state=1) \n",
    "\n",
    "    # check and report the ratio of real-to-fake news in both training and testing sets\n",
    "    print(\"The ratio of real and fake news in training sets:\")\n",
    "    print(pd.Series(y_train).value_counts(normalize=True), '\\n')\n",
    "    print(\"The ratio of real and fake news in testing sets:\")\n",
    "    print(pd.Series(y_test).value_counts(normalize=True), '\\n')\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Training Logistic Regression Models with Adding Bi-Grams to the Model \n",
    "● Prepare pipeline building up using sklearn’s CounterVectorizer and TfidfVectorizer.\\\n",
    "● Add bigram in both vectorizers.\\\n",
    "● Train logistic regression classifiers using the training set.\\\n",
    "● Compute (i) accuracy, (ii) precision and (iii) recall based on the testing set.\\\n",
    "● Save models in a .pkl file using joblib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train a logistic regression classifier with count vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_count(x_train, x_test, y_train, y_test):\n",
    "    \"\"\" \n",
    "    Train a logistic regression classifier with count vectorizer.\n",
    "\n",
    "    :param x_train: pandas Dataframe\n",
    "    :param x_test: pandas Dataframe\n",
    "    :param y_train: pandas Dataframe\n",
    "    :param y_test: pandas Dataframe\n",
    "    :returns sklearn model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print('Logistic regression classifier with count vectorizer, model training...')\n",
    "\n",
    "    # creating a pipeline\n",
    "    vectorizer = ColumnTransformer([('title_vect', CountVectorizer(ngram_range=(1, 2)), 'title'),\n",
    "                                    ('text_vect', CountVectorizer(ngram_range=(1, 2)), 'text')\n",
    "                                ])\n",
    "    clf = Pipeline([\n",
    "        ('vec', vectorizer),\n",
    "        ('log', LogisticRegression(max_iter=1000)) \n",
    "    ])\n",
    "\n",
    "    # Use the training data to fit the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Model training is over.\\n')\n",
    "    \n",
    "    # make prediction\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # evaluation\n",
    "    print('Evaluation report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save the model into a file named 'count_LR_model.pkl'\n",
    "    joblib.dump(clf, \"count_LR_model.pkl\")\n",
    "\n",
    "    return clf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Train a logistic regression classifier with tfidf vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_tfidf(x_train, x_test, y_train, y_test):\n",
    "    \"\"\" \n",
    "    Train a logistic regression classifier with tfidf vectorizer.\n",
    "\n",
    "    :param x_train: pandas Dataframe\n",
    "    :param x_test: pandas Dataframe\n",
    "    :param y_train: pandas Dataframe\n",
    "    :param y_test: pandas Dataframe\n",
    "    :returns sklearn model\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    print('Logistic regression classifier with tfidf vectorizer, model training...')\n",
    "\n",
    "    # creating a pipeline\n",
    "    vectorizer = ColumnTransformer([('title_vect', TfidfVectorizer(ngram_range=(1, 2)), 'title'),\n",
    "                                    ('text_vect', TfidfVectorizer(ngram_range=(1, 2)), 'text')\n",
    "                                ])\n",
    "    clf = Pipeline([\n",
    "        ('vec', vectorizer),\n",
    "        ('log', LogisticRegression()) # The logistic regression using default params\n",
    "    ])\n",
    "\n",
    "    # Use the training data to fit the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Model training is over.\\n')\n",
    "\n",
    "    # make prediction\n",
    "    y_pred = clf.predict(x_test)\n",
    "\n",
    "    # evaluation\n",
    "    print('Evaluation report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Save the model into a file named 'tfidf_LR_model.pkl'\n",
    "    joblib.dump(clf, \"tfidf_LR_model.pkl\")\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Run and compare all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Prerpocessing...\n",
      "The ratio of real and fake news in training sets:\n",
      "REAL    0.500592\n",
      "FAKE    0.499408\n",
      "Name: label, dtype: float64 \n",
      "\n",
      "The ratio of real and fake news in testing sets:\n",
      "REAL    0.500395\n",
      "FAKE    0.499605\n",
      "Name: label, dtype: float64 \n",
      "\n",
      "Logistic regression classifier with count vectorizer, model training...\n",
      "Model training is over.\n",
      "\n",
      "Evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.92      0.95      0.94       633\n",
      "        REAL       0.95      0.92      0.93       634\n",
      "\n",
      "    accuracy                           0.94      1267\n",
      "   macro avg       0.94      0.94      0.94      1267\n",
      "weighted avg       0.94      0.94      0.94      1267\n",
      "\n",
      "Logistic regression classifier with tfidf vectorizer, model training...\n",
      "Model training is over.\n",
      "\n",
      "Evaluation report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        FAKE       0.92      0.93      0.93       633\n",
      "        REAL       0.93      0.92      0.93       634\n",
      "\n",
      "    accuracy                           0.93      1267\n",
      "   macro avg       0.93      0.93      0.93      1267\n",
      "weighted avg       0.93      0.93      0.93      1267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = preProcess('./news.csv')\n",
    "count_LR_model = logistic_regression_count(x_train, x_test, y_train, y_test)\n",
    "tfidf_LR_model = logistic_regression_tfidf(x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Model**      | **Accuracy** | **Precision (fake)** | **Recall (fake)** | **Percision (real)** | **Recall (real)** |\n",
    "|----------------|--------------|----------------------|-------------------|----------------------|-------------------|\n",
    "| Logistic-Count | 0.94         | 0.92                 | 0.95              | 0.95                 | 0.92              |\n",
    "| Logistic-Tfidf | 0.93         | 0.92                 | 0.93              | 0.93                 | 0.92              |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myML39",
   "language": "python",
   "name": "myml39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
